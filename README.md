# üöÄ Plateforme de Monitoring Streaming & Batch
Modern Data Stack ‚Äì Pipeline de Donn√©es pour l'Analyse d'Activit√© en Temps R√©el

[![Kafka](https://img.shields.io/badge/Apache-Kafka-black?style=for-the-badge&logo=apachekafka)](https://kafka.apache.org/)
[![Spark](https://img.shields.io/badge/Apache-Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![BigQuery](https://img.shields.io/badge/Google-BigQuery-blue?style=for-the-badge&logo=googlecloud)](https://cloud.google.com/bigquery)
[![MongoDB](https://img.shields.io/badge/MongoDB-47A248?style=for-the-badge&logo=mongodb&logoColor=white)](https://www.mongodb.com/)
[![dbt](https://img.shields.io/badge/dbt-orange?style=for-the-badge&logo=dbt&logoColor=white)](https://www.getdbt.com/)
[![Airflow](https://img.shields.io/badge/Apache-Airflow-017CEE?style=for-the-badge&logo=apacheairflow&logoColor=white)](https://airflow.apache.org/)
[![Live Dashboard](https://img.shields.io/badge/QlikSense-Dashboard-009845?style=for-the-badge&logo=qlik&logoColor=white)](https://yr9pfbp2oxzezb5.fr.qlikcloud.com/sense/app/05d3b740-87d3-4ba7-9215-2f8479c83132)

---

## ‚≠ê Features

- **Architecture Lambda** compl√®te (Streaming & Batch)
- Ingestion temps r√©el via **Kafka & Schema Registry** (Avro)
- Traitement distribu√© avec **PySpark Structured Streaming**
- Data Warehouse Cloud sur **Google BigQuery**
- Orchestration compl√®te avec **Apache Airflow**
- Transformations modulaires et tests avec **dbt**
- Dashboards interactifs **Streamlit** (Op√©rationnel) & **QlikSense** (Analytique)
- Environnement 100% reproductible via **Docker**

---

## üß† Architecture Lambda & Concepts

Ce projet impl√©mente une **Architecture Lambda**, une approche robuste pour traiter massivement les donn√©es en combinant deux flux :

### 1. Speed Layer (Temps R√©el)
- **Flux** : Kafka ‚Üí PySpark Streaming ‚Üí MongoDB.
- **Pourquoi le "compte-goutte" (Streaming) ?** : Pour obtenir une latence minimale. On traite chaque √©v√©nement d√®s qu'il arrive pour d√©tecter des anomalies ou surveiller l'activit√© en direct sur le dashboard Streamlit. C'est id√©al pour la r√©activit√© imm√©diate.

### 2. Batch Layer (Historique)
- **Flux** : MongoDB ‚Üí Airflow ‚Üí BigQuery ‚Üí dbt.
- **R√¥le** : Fournir une vue exhaustive et ultra-pr√©cise de toutes les donn√©es historiques. C'est ici que dbt intervient pour transformer les donn√©es brutes en KPIs fiables pour le dashboard QlikSense.

### 3. Serving Layer
- Fournit les r√©sultats aux utilisateurs via les dashboards (Streamlit pour le live, Qlik pour l'analytique).

---

## üèóÔ∏è Architecture Overview

Cette plateforme traite des flux massifs d'√©v√©nements (activit√© utilisateur et modifications Wikimedia) pour fournir des indicateurs de performance (KPIs) en temps r√©el et des analyses historiques.

### üîß Composants

| Couche | Technologie | R√¥le |
|-------|------------|---------|
| **Ingestion** | Kafka, Schema Registry | Collecte des flux Avro (User Activity & Wikimedia) |
| **Streaming** | PySpark | Agr√©gations glissantes, Watermarking & Nettoyage |
| **Stockage** | MongoDB & BigQuery | Raw Data Lake (NoSQL) & Data Warehouse (Cloud) |
| **Orchestration** | Airflow | Scheduling des DAGs, jobs batch et dbt |
| **Transformation** | dbt Core | Mod√©lisation SQL, KPIs & Qualit√© de donn√©es |
| **Visualisation** | Streamlit / Qlik | Dashboards temps r√©el et pilotage BI |

---

## üìä R√©sultats Analytiques & KPIs

Le pipeline produit des tables pr√™tes pour l'analyse dans BigQuery :

### **`monitoring_datalake.fct_daily_user_metrics`**

#### Indicateurs Principaux
- **Volume d'√©v√©nements** ‚Üí `event_count`
- **Utilisateurs Uniques** ‚Üí `unique_users`

#### Dimensions d'Analyse
- `activity_date`
- `event_type` (CLICK, VIEW, PURCHASE, etc.)

---

## üìà Dashboard Preview

Acc√©dez aux interfaces de contr√¥le de la plateforme :

| Outil | URL / Acc√®s | Utilit√© |
| :--- | :--- | :--- |
| **QlikSense** | [Live Dashboard](https://yr9pfbp2oxzezb5.fr.qlikcloud.com/sense/app/05d3b740-87d3-4ba7-9215-2f8479c83132) | Dashboard Analytique (BigQuery) |
| **Streamlit** | [http://localhost:8501](http://localhost:8501) | Dashboard Temps R√©el (MongoDB) |
| **Airflow** | [http://localhost:8082](http://localhost:8082) | Orchestration & Monitoring des Pipelines |
| **Kafka UI** | [http://localhost:9021](http://localhost:9021) | Gestion des Topics & Sch√©mas Avro |
| **Spark UI** | [http://localhost:9090](http://localhost:9090) | Monitoring des jobs de Streaming |

---

## üîê Data Quality (DataOps via dbt)

La fiabilit√© des donn√©es est assur√©e par des tests automatis√©s dbt :
- `not_null` sur les cl√©s primaires et dimensions critiques.
- Tests de validit√© des KPIs.

**Status:** ‚úîÔ∏è *PASS ‚Äî Tous les tests de qualit√© valid√©s*

---

## üõ†Ô∏è Tech Stack

### Langages & Frameworks
- **Python 3.9+** (Ingestion, Spark, Streamlit)
- **SQL** (BigQuery Standard SQL, dbt)
- **Avro** (S√©rialisation des donn√©es)

### Infrastructure
- **Docker & Docker Compose**
- **Google Cloud Platform** (BigQuery)
- **Confluent Kafka Stack**

---

## üß© Installation & D√©marrage

```bash
# 1. Lancer l'infrastructure (Kafka, Spark, Airflow, Mongo)
docker-compose up -d

# 2. Installer les d√©pendances Python
pip install -r requirements.txt

# 3. Lancer les producteurs de donn√©es
python src/ingestion/main.py           # Activit√© utilisateur
python src/ingestion/wikimedia_producer.py # Flux Wikimedia
```

### Configuration dbt
Cr√©ez ou √©ditez votre fichier `~/.dbt/profiles.yml` :
```yaml
monitoring_platform:
  target: dev
  outputs:
    dev:
      type: bigquery
      method: service-account
      keyfile: "config/gcp/service-account.json"
      project: "effidic-stage-2026"
      dataset: "monitoring_datalake"
      threads: 4
```

---

## üìö Documentation Avanc√©e

*   üîç **[Guide de Connexion BigQuery](docs/BIGQUERY_CONNECTION_GUIDE.md)** : Param√®tres Simba/ODBC pour BI.
*   üìÇ **[Sources des Donn√©es](docs/DATA_SOURCES.md)** : Origine et signification des donn√©es.
*   üöÄ **[Rapport d'Industrialisation](docs/INDUSTRIALIZATION.md)** : S√©curit√©, CI/CD, FinOps.

---

## üë®‚Äçüíª Author

**NGUETTE FANE Gad**
Data Engineer ‚Äì Plateforme de Monitoring Streaming

üìß Contact : [nguettefanegad@gmail.com]